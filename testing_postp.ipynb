{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posprocessing a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_MEM_FRACTION=.6\n"
     ]
    }
   ],
   "source": [
    "%env XLA_PYTHON_CLIENT_MEM_FRACTION=.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 10:58:46.379965: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/mi/minvernizzi/.local/lib\n",
      "2023-01-24 10:58:46.380052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/mi/minvernizzi/.local/lib\n",
      "2023-01-24 10:58:46.380059: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c387524f70448cb8f87cddb89882ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lenses\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from typing import cast\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from flox.util import key_chain\n",
    "from flox.flow import Pipe\n",
    "# from flox._src.flow.api import Inverted, Transform, Transformed, bind\n",
    "import equinox as eqx\n",
    "\n",
    "from rigid_flows.flow import build_flow, RigidWithAuxiliary\n",
    "from rigid_flows.data import Data, DataWithAuxiliary\n",
    "from rigid_flows.density import OpenMMDensity\n",
    "from rigid_flows.specs import FlowSpecification, CouplingSpecification, ExperimentSpecification\n",
    "# from rigid_flows.density import PositionPrior, RotationPrior\n",
    "from rigid_flows.utils import jit_and_cleanup_cache, scanned_vmap\n",
    "\n",
    "chain = key_chain(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    return jax.tree_util.tree_reduce(\n",
    "        lambda s, n: s + n.size if eqx.is_array(n) else s, model, jnp.zeros((), dtype=jnp.int32)).item()\n",
    "\n",
    "hist_kwargs = {\"bins\": \"auto\", \"density\": True, \"alpha\": 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "can only convert an array of size 1 to a Python scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m data \u001b[39m=\u001b[39m Data\u001b[39m.\u001b[39mfrom_specs(specs\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtarget, target\u001b[39m.\u001b[39mbox)\n\u001b[1;32m     21\u001b[0m flow \u001b[39m=\u001b[39m build_flow(\u001b[39mnext\u001b[39m(chain), specs\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mauxiliary_shape, specs\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mflow)\n\u001b[1;32m     22\u001b[0m flow \u001b[39m=\u001b[39m cast(\n\u001b[1;32m     23\u001b[0m             Pipe[DataWithAuxiliary, RigidWithAuxiliary],\n\u001b[0;32m---> 24\u001b[0m             eqx\u001b[39m.\u001b[39;49mtree_deserialise_leaves(\n\u001b[1;32m     25\u001b[0m                 pretrained_model_path, flow\n\u001b[1;32m     26\u001b[0m             ),\n\u001b[1;32m     27\u001b[0m         )\n\u001b[1;32m     29\u001b[0m training_data_size \u001b[39m=\u001b[39m \u001b[39m100_000\u001b[39m \u001b[39mif\u001b[39;00m specs\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mbase\u001b[39m.\u001b[39mnum_samples \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m specs\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mbase\u001b[39m.\u001b[39mnum_samples\n\u001b[1;32m     30\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtot flow parameters: \u001b[39m\u001b[39m{\u001b[39;00mcount_params(flow)\u001b[39m:\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/flox/lib/python3.10/site-packages/equinox/serialisation.py:319\u001b[0m, in \u001b[0;36mtree_deserialise_leaves\u001b[0;34m(path_or_file, like, filter_spec, is_leaf)\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[39mreturn\u001b[39;00m spec(f, y)\n\u001b[1;32m    317\u001b[0m         \u001b[39mreturn\u001b[39;00m _ordered_tree_map(__deserialise, x, is_leaf\u001b[39m=\u001b[39mis_leaf)\n\u001b[0;32m--> 319\u001b[0m     out \u001b[39m=\u001b[39m _ordered_tree_map(_deserialise, filter_spec, like)\n\u001b[1;32m    320\u001b[0m jtu\u001b[39m.\u001b[39mtree_map(_assert_same, out, like, is_leaf\u001b[39m=\u001b[39mis_leaf)\n\u001b[1;32m    321\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/flox/lib/python3.10/site-packages/equinox/serialisation.py:26\u001b[0m, in \u001b[0;36m_ordered_tree_map\u001b[0;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[1;32m     24\u001b[0m leaves, treedef \u001b[39m=\u001b[39m jtu\u001b[39m.\u001b[39mtree_flatten(tree, is_leaf)\n\u001b[1;32m     25\u001b[0m all_leaves \u001b[39m=\u001b[39m [leaves] \u001b[39m+\u001b[39m [treedef\u001b[39m.\u001b[39mflatten_up_to(r) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m rest]\n\u001b[0;32m---> 26\u001b[0m \u001b[39mreturn\u001b[39;00m treedef\u001b[39m.\u001b[39;49munflatten(f(\u001b[39m*\u001b[39;49mxs) \u001b[39mfor\u001b[39;49;00m xs \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49mall_leaves))\n",
      "File \u001b[0;32m~/miniconda3/envs/flox/lib/python3.10/site-packages/equinox/serialisation.py:26\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     24\u001b[0m leaves, treedef \u001b[39m=\u001b[39m jtu\u001b[39m.\u001b[39mtree_flatten(tree, is_leaf)\n\u001b[1;32m     25\u001b[0m all_leaves \u001b[39m=\u001b[39m [leaves] \u001b[39m+\u001b[39m [treedef\u001b[39m.\u001b[39mflatten_up_to(r) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m rest]\n\u001b[0;32m---> 26\u001b[0m \u001b[39mreturn\u001b[39;00m treedef\u001b[39m.\u001b[39munflatten(f(\u001b[39m*\u001b[39;49mxs) \u001b[39mfor\u001b[39;00m xs \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mall_leaves))\n",
      "File \u001b[0;32m~/miniconda3/envs/flox/lib/python3.10/site-packages/equinox/serialisation.py:317\u001b[0m, in \u001b[0;36mtree_deserialise_leaves.<locals>._deserialise\u001b[0;34m(spec, x)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__deserialise\u001b[39m(y):\n\u001b[1;32m    315\u001b[0m     \u001b[39mreturn\u001b[39;00m spec(f, y)\n\u001b[0;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m _ordered_tree_map(__deserialise, x, is_leaf\u001b[39m=\u001b[39;49mis_leaf)\n",
      "File \u001b[0;32m~/miniconda3/envs/flox/lib/python3.10/site-packages/equinox/serialisation.py:26\u001b[0m, in \u001b[0;36m_ordered_tree_map\u001b[0;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[1;32m     24\u001b[0m leaves, treedef \u001b[39m=\u001b[39m jtu\u001b[39m.\u001b[39mtree_flatten(tree, is_leaf)\n\u001b[1;32m     25\u001b[0m all_leaves \u001b[39m=\u001b[39m [leaves] \u001b[39m+\u001b[39m [treedef\u001b[39m.\u001b[39mflatten_up_to(r) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m rest]\n\u001b[0;32m---> 26\u001b[0m \u001b[39mreturn\u001b[39;00m treedef\u001b[39m.\u001b[39;49munflatten(f(\u001b[39m*\u001b[39;49mxs) \u001b[39mfor\u001b[39;49;00m xs \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49mall_leaves))\n",
      "File \u001b[0;32m~/miniconda3/envs/flox/lib/python3.10/site-packages/equinox/serialisation.py:26\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     24\u001b[0m leaves, treedef \u001b[39m=\u001b[39m jtu\u001b[39m.\u001b[39mtree_flatten(tree, is_leaf)\n\u001b[1;32m     25\u001b[0m all_leaves \u001b[39m=\u001b[39m [leaves] \u001b[39m+\u001b[39m [treedef\u001b[39m.\u001b[39mflatten_up_to(r) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m rest]\n\u001b[0;32m---> 26\u001b[0m \u001b[39mreturn\u001b[39;00m treedef\u001b[39m.\u001b[39munflatten(f(\u001b[39m*\u001b[39;49mxs) \u001b[39mfor\u001b[39;00m xs \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mall_leaves))\n",
      "File \u001b[0;32m~/miniconda3/envs/flox/lib/python3.10/site-packages/equinox/serialisation.py:315\u001b[0m, in \u001b[0;36mtree_deserialise_leaves.<locals>._deserialise.<locals>.__deserialise\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__deserialise\u001b[39m(y):\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mreturn\u001b[39;00m spec(f, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/flox/lib/python3.10/site-packages/equinox/serialisation.py:137\u001b[0m, in \u001b[0;36mdefault_deserialise_filter_spec\u001b[0;34m(f, x)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m    136\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, (\u001b[39mbool\u001b[39m, \u001b[39mfloat\u001b[39m, \u001b[39mcomplex\u001b[39m, \u001b[39mint\u001b[39m)):\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mload(f)\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m    138\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, experimental\u001b[39m.\u001b[39mStateIndex):\n\u001b[1;32m    139\u001b[0m     \u001b[39m# Make a new StateIndex. If we happen to load some state then we don't\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[39m# want to affect the `like` as a side-effect.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     y \u001b[39m=\u001b[39m experimental\u001b[39m.\u001b[39mStateIndex(inference\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39minference)\n",
      "\u001b[0;31mValueError\u001b[0m: can only convert an array of size 1 to a Python scalar"
     ]
    }
   ],
   "source": [
    "# logdir_path = 'jonas_logdir/antelope_N16_T50_2023-01-21_21:55:41' #good one - ESS 3.52%\n",
    "# logdir_path = 'jonas_logdir/dragonfly_N16_2023-01-21_17:56:08' #good one\n",
    "logdir_path = 'jonas_logdir/antelope_N16_2023-01-21_18:04:22' #ESS 11.22%\n",
    "# logdir_path = 'jonas_logdir/dragonfly_N128_2023-01-22_09:12:03'\n",
    "# logdir_path = 'jonas_logdir/'\n",
    "# logdir_path += 'tuna_N16_noaux_2023-01-23_23:55:54'\n",
    "stage = 0\n",
    "epoch = 9\n",
    "specs_path = f\"{logdir_path}/config.yaml\"\n",
    "pretrained_model_path = f'{logdir_path}/training_stage_{stage}/epoch_{epoch}/model.eqx'\n",
    "\n",
    "\n",
    "specs = ExperimentSpecification.load_from_file(specs_path)\n",
    "specs = lenses.bind(specs).model.base.path.set(specs.model.base.path+'/eval_100')\n",
    "\n",
    "base = OpenMMDensity.from_specs(specs.model.auxiliary_shape, specs.model.base)\n",
    "target = OpenMMDensity.from_specs(specs.model.auxiliary_shape, specs.model.target)\n",
    "model = base.omm_model.model\n",
    "\n",
    "data = Data.from_specs(specs.model.target, target.box)\n",
    "flow = build_flow(next(chain), specs.model.auxiliary_shape, specs.model.flow)\n",
    "flow = cast(\n",
    "            Pipe[DataWithAuxiliary, RigidWithAuxiliary],\n",
    "            eqx.tree_deserialise_leaves(\n",
    "                pretrained_model_path, flow\n",
    "            ),\n",
    "        )\n",
    "\n",
    "training_data_size = 100_000 if specs.model.base.num_samples is None else specs.model.base.num_samples\n",
    "print(f'tot flow parameters: {count_params(flow):_}')\n",
    "print(f'MD training datapoints = {training_data_size:_}')\n",
    "print(f'MD eval datapoints = {base.data.pos.shape[0]:_}')\n",
    "print(f'batchs per epoch = {specs.train[0].num_iters_per_epoch}')\n",
    "print(f'batch size = {specs.train[0].num_samples}')\n",
    "print(f'data fraction: {specs.train[0].num_epochs*specs.train[0].num_samples*specs.train[0].num_iters_per_epoch/training_data_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_deltaF, reference_deltaF_std = None, None\n",
    "\n",
    "if specs.model.base.temperature == specs.model.target.temperature:\n",
    "    reference_deltaF, reference_deltaF_std = 0, 0\n",
    "elif specs.model.base.num_molecules == 16:\n",
    "    if specs.model.base.temperature == 250 and specs.model.target.temperature == 100:\n",
    "        reference_deltaF, reference_deltaF_std = -666.09897990553, 0.0558899 # MBAR, 10_000 samples, 5 replicas\n",
    "    elif specs.model.base.temperature == 250 and specs.model.target.temperature == 50:\n",
    "        reference_deltaF, reference_deltaF_std = -1818.2199636389134, 0.0632776 # MBAR, 10_000 samples, 10 replicas\n",
    "elif specs.model.base.num_molecules == 128:\n",
    "    if specs.model.base.temperature == 250 and specs.model.target.temperature == 100:\n",
    "        reference_deltaF, reference_deltaF_std = -5314.324317927606, 0.0944014 # MBAR, 10_000 samples, 10 replicas\n",
    "    elif specs.model.base.temperature == 250 and specs.model.target.temperature == 50:\n",
    "        reference_deltaF, reference_deltaF_std = -14522.10556489954, 0.135 # MBAR, 10_000 samples, 20 replicas\n",
    "\n",
    "reference_deltaF, reference_deltaF_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10_000\n",
    "batch_size = 128\n",
    "\n",
    "keys = jax.random.split(next(chain), num_samples)\n",
    "base_tr = jax.vmap(base.sample)(keys)\n",
    "\n",
    "mapped_tr = scanned_vmap(flow.inverse, batch_size)(base_tr.obj)\n",
    "\n",
    "keys = jax.random.split(next(chain), num_samples)\n",
    "target_tr = jax.vmap(target.sample)(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2Dview(data_tr: DataWithAuxiliary, title: str, toPBC: bool = True, skip: int = 10):\n",
    "    model.plot_2Dview(data_tr.obj.pos.reshape(-1, model.n_atoms, 3)[::skip], toPBC=toPBC, title=title)\n",
    "\n",
    "plot_2Dview(base_tr, title='base')\n",
    "plot_2Dview(mapped_tr, title='mapped')\n",
    "plot_2Dview(target_tr, title='base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## closer look at the center of mass\n",
    "com_pos = mapped_tr.obj.pos.mean(axis=(1,2))\n",
    "plt.plot(com_pos, '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ess(logw):\n",
    "    return jnp.exp(2*jax.scipy.special.logsumexp(logw)-jax.scipy.special.logsumexp(2*logw))\n",
    "\n",
    "## NB: base_tr.ldj = jax.vmap(base.potential)(base_tr.obj)\n",
    "logw = base_tr.ldj + mapped_tr.ldj - jax.vmap(target.potential)(mapped_tr.obj)\n",
    "\n",
    "plt.hist(jnp.exp(logw-logw.max()), bins=100)\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "print(f'ESS = {ess(logw):g}  ->  {ess(logw)/len(logw):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ene_fn = jax.vmap(target.potential)\n",
    "base_ene = ene_fn(base_tr.obj)\n",
    "mapped_ene = ene_fn(mapped_tr.obj)\n",
    "target_ene = ene_fn(target_tr.obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(base_ene, **hist_kwargs, label='base')\n",
    "plt.hist(mapped_ene, **hist_kwargs, label='mapped')\n",
    "plt.hist(target_ene, **hist_kwargs, label='target')\n",
    "plt.hist(mapped_ene, weights=jnp.exp(logw-jax.scipy.special.logsumexp(logw)), bins=75, histtype='step', density=True, label='reweighted')\n",
    "plt.xlabel('total energy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ene_label = 'omm'\n",
    "scaling = 1\n",
    "if ene_label == 'omm':\n",
    "    scaling = target.omm_model.kbT\n",
    "base_ene2 = target.compute_energies(base_tr.obj, True, False, True)[ene_label] * scaling\n",
    "target_ene2 = target.compute_energies(target_tr.obj, True, False, True)[ene_label] * scaling\n",
    "mapped_ene2 = target.compute_energies(mapped_tr.obj, True, False, True)[ene_label] * scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(base_ene2, **hist_kwargs, label='base')\n",
    "plt.hist(mapped_ene2, **hist_kwargs, label='mapped')\n",
    "plt.hist(target_ene2, **hist_kwargs, label='target')\n",
    "plt.hist(mapped_ene2, weights=jnp.exp(logw-jax.scipy.special.logsumexp(logw)), bins=75, histtype='step', density=True, label='reweighted')\n",
    "plt.xlabel(ene_label + ' energy [kJ/mol]') #it's kJ/mol only for omm energies\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO add reweighted rdf\n",
    "\n",
    "r_range = [0.2, np.diag(model.box).min()]\n",
    "n_bins = 300\n",
    "plt.title('Oxygen-Oxygen')\n",
    "model.plot_rdf(base_tr.obj.pos.reshape(-1, model.n_atoms, 3), r_range=r_range, n_bins=n_bins, label='base')\n",
    "model.plot_rdf(mapped_tr.obj.pos.reshape(-1, model.n_atoms, 3), r_range=r_range, n_bins=n_bins, label='mapped')\n",
    "model.plot_rdf(target_tr.obj.pos.reshape(-1, model.n_atoms, 3), r_range=r_range, n_bins=n_bins, label='target')\n",
    "plt.axvline(model.box.max()/2, c='k', ls=':', alpha=.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TFEP\n",
    "deltaF = (jnp.log(len(logw)) - jax.scipy.special.logsumexp(logw)).item()\n",
    "print(f'Estimated deltaF from LFEP (above) = {deltaF:g}')\n",
    "if reference_deltaF is not None:\n",
    "    print(f'                  Reference deltaF = {reference_deltaF:g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "@partial(jax.jit, static_argnames=[\"num_samples\", \"base\", \"batch_size\"])\n",
    "def estimate_deltaF(key, num_samples, base=base, batch_size=128):\n",
    "    keys = jax.random.split(key, num_samples)\n",
    "    base_tr = jax.vmap(base.sample)(keys)\n",
    "    mapped_tr = scanned_vmap(flow.inverse, batch_size)(base_tr.obj)\n",
    "    logw = base_tr.ldj + mapped_tr.ldj - jax.vmap(target.potential)(mapped_tr.obj)\n",
    "    return (jnp.log(len(logw)) - jax.scipy.special.logsumexp(logw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_from_training = False #this gives a biased estimate, always lower\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "iterations = 10\n",
    "num_samples = base.data.pos.shape[0]\n",
    "\n",
    "deltaFs = np.zeros(iterations)\n",
    "# for i in trange(iterations):\n",
    "#     deltaFs[i] = estimate_deltaF(next(chain), num_samples)\n",
    "#     print(deltaFs[i])\n",
    "print(f'deltaF = {deltaFs.mean()} +/- {deltaFs.std():g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'deltaF = {deltaFs.mean()} +/- {deltaFs.std():g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @partial(jax.jit, static_argnames=[\"start\", \"num_samples\", \"base\", \"batch_size\"])\n",
    "# def estimate_deltaF_idx(key, start, num_samples, base=base, batch_size=128):\n",
    "#     keys = jax.random.split(key, num_samples)\n",
    "#     base_tr = jax.vmap(base.sample_idx)(keys, jnp.arange(start, start+num_samples))\n",
    "#     mapped_tr = scanned_vmap(flow.inverse, batch_size)(base_tr.obj)\n",
    "#     logw = base_tr.ldj + mapped_tr.ldj - jax.vmap(target.potential)(mapped_tr.obj)\n",
    "#     return (jnp.log(len(logw)) - jax.scipy.special.logsumexp(logw))\n",
    "\n",
    "# deltaFs = np.zeros(iterations)\n",
    "# for i in trange(iterations):\n",
    "#     deltaFs[i] = estimate_deltaF_idx(next(chain), i*num_samples, num_samples)\n",
    "#     print(deltaFs[i])\n",
    "# print(f'deltaF = {deltaFs.mean():g} +/- {deltaFs.std():g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim = [0, len(deltaFs)]\n",
    "plt.plot(deltaFs, '.', c='orange', label='LFEP')\n",
    "x = 2 * [deltaFs.mean()]\n",
    "plt.fill_between(xlim, x-deltaFs.std(), x+deltaFs.std(), color='orange', alpha=0.3)\n",
    "plt.axhline(deltaFs.mean(), c='orange')\n",
    "if reference_deltaF is not None:\n",
    "    plt.axhline(reference_deltaF, c='k', ls=\":\", label='MBAR reference')\n",
    "    x = np.array(2 * [reference_deltaF])\n",
    "    plt.fill_between(xlim, x-reference_deltaF_std, x+reference_deltaF_std, color='k', alpha=0.1)\n",
    "plt.xlim(xlim)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaFs.mean()-reference_deltaF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_mapped_tr = scanned_vmap(flow.forward, batch_size)(target_tr.obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_back_mapped_tr = scanned_vmap(flow.inverse, batch_size)(back_mapped_tr.obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2Dview(base_tr, title='base')\n",
    "plot_2Dview(back_mapped_tr, title='back_mapped')\n",
    "plot_2Dview(target_tr, title='base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NB: base_tr.ldj = jax.vmap(base.potential)(base_tr.obj)\n",
    "back_logw = target_tr.ldj + back_mapped_tr.ldj - jax.vmap(base.potential)(back_mapped_tr.obj) #-phi_F\n",
    "\n",
    "plt.hist(jnp.exp(back_logw-back_logw.max()), bins=100)\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "print(f'ESS = {ess(back_logw):g}  ->  {ess(back_logw)/len(back_logw):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_mapped_ene2 = target.compute_energies(back_mapped_tr.obj, True, False, True)[ene_label] * scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(base_ene2, **hist_kwargs, label='base')\n",
    "plt.hist(mapped_ene2, **hist_kwargs, label='mapped', histtype='step')\n",
    "plt.hist(target_ene2, **hist_kwargs, label='target')\n",
    "plt.hist(back_mapped_ene2, **hist_kwargs, label='back_mapped', histtype='step')\n",
    "# plt.hist(mapped_ene2, weights=jnp.exp(logw-jax.scipy.special.logsumexp(logw)), bins=75, histtype='step', density=True, label='reweighted')\n",
    "plt.xlabel(ene_label + ' energy [kJ/mol]') #it's kJ/mol only for omm energies\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## back_TFEP\n",
    "back_deltaF = (jnp.log(len(back_logw)) - jax.scipy.special.logsumexp(back_logw)).item()\n",
    "print(f'Estimated deltaF from LFEP (below) = {back_deltaF:g}')\n",
    "if reference_deltaF is not None:\n",
    "    print(f'                  Reference deltaF = {reference_deltaF:g}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_k = np.array([mapped_tr.obj.pos.shape[0], back_mapped_tr.obj.pos.shape[0]])\n",
    "\n",
    "u_kn = np.empty((2, N_k.sum()))\n",
    "u_kn[0] = np.concatenate([base_tr.ldj, logw - base_tr.ldj])\n",
    "u_kn[1] = np.concatenate([target_tr.ldj, back_logw - target_tr.ldj])\n",
    "\n",
    "N_k.shape, u_kn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymbar\n",
    "\n",
    "mbar = pymbar.MBAR(u_kn, N_k, n_bootstraps=100, solver_protocol='robust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('flox')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52d865f241f5cf4532d2b38dc6618aea3fdd872b067fcdc4aedd37cb5878aec8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
